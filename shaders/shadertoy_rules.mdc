---
description: 
globs: *.glsl
alwaysApply: false
---
# BICE Box ShaderToy GLSL Guide

This document provides guidelines and essential information for creating GLSL shaders compatible with the BICE Box `ShaderToyLite.js` framework. The goal is to enable developers (and LLMs) to write new visual effects that integrate seamlessly.

## Core Concepts

- **ShaderToyLite Integration**: BICE Box uses a custom `ShaderToyLite.js` implementation. Shaders are written in GLSL ES 3.00.
- **File Location**: All shader files (.glsl) should be placed in the `bice-box-effects/shaders/` directory.
- **Effect Definition**: Visual effects are defined in `.json` files within the `bice-box-effects/effects/` directory. These JSON files link to the shader files.

## Standard Uniforms (Provided by ShaderToyLite.js)

The following uniforms are automatically provided to your shaders. **Do NOT redeclare these in your shader code.**

```glsl
uniform vec3  iResolution;           // Viewport resolution (in pixels). Use iResolution.xy for 2D.
uniform float iTime;                 // Shader playback time (in seconds).
uniform float iTimeDelta;            // Render time (in seconds) for the last frame.
uniform float iFrameRate;            // Shader frame rate (typically 60).
uniform int   iFrame;                // Shader playback frame count.
uniform vec4  iMouse;                // Mouse pixel coordinates:
                                     //   xy: current (if MLB down)
                                     //   zw: click position (while MLB down)
uniform vec4  iDate;                 // (year, month, day, unixtime in seconds)
uniform float iSampleRate;           // Audio sample rate (e.g., 44100).

// Channel Inputs (for multi-pass shaders or texture inputs)
uniform sampler2D iChannel0;         // Input channel 0
uniform sampler2D iChannel1;         // Input channel 1
uniform sampler2D iChannel2;         // Input channel 2
uniform sampler2D iChannel3;         // Input channel 3
uniform float     iChannelTime[4];   // Channel playback time (in seconds) - rarely used directly.
uniform vec3      iChannelResolution[4]; // Channel resolution (in pixels) - rarely used directly.

// Audio-Reactive Uniforms
uniform float     iRMSInput;           // Input RMS (Root Mean Square) audio level (0.0 to 1.0+).
uniform float     iRMSOutput;          // Output RMS audio level (0.0 to 1.0+).
uniform sampler2D iAudioTexture;       // Texture containing audio data (see details below).
```

### `iAudioTexture` Details

`iAudioTexture` is a crucial uniform for creating audio-reactive visuals. It's a 2D texture (typically 1024x2 pixels) structured as follows:

-   **Row 0 (UV y-coordinate ~0.25): FFT Data**
    -   Contains frequency spectrum data.
    -   The data is pre-processed: magnitudes are logarithmically scaled.
    -   Values are typically in a range like 0.0 to 1.0+ after normalization in `VisualizationCanvas.js`.
    -   The X-axis (`u` from 0.0 to 1.0) maps to frequency bins from low to high.
    -   `VisualizationCanvas.js` prepares this row by taking 1024 FFT samples, normalizing them (often `fftData[i] * 100`), and clamping to 0-255 before packing into the R channel of an RGBA texture. Shaders sample this (e.g. `.r` or `.x`) and should typically expect values that can be scaled for visual use.
-   **Row 1 (UV y-coordinate ~0.75): Waveform Data**
    -   Contains raw audio waveform data (time domain).
    -   Values are normalized from their original -1.0 to 1.0 range to a 0.0 to 1.0 range for texture storage. Shaders should map this back if necessary: `(textureVal * 2.0) - 1.0`.
    -   The X-axis (`u` from 0.0 to 1.0) maps to time.
    -   `VisualizationCanvas.js` prepares this row by taking 1024 waveform samples, normalizing `(sample * 0.5 + 0.5) * 255`, and packing into the R channel.

**Sampling `iAudioTexture`:**

You can use `texture()` or `texelFetch()`. `texture()` samples the center of texels by default with normalized coordinates. For a 2-pixel high texture where row 0 is FFT and row 1 is Waveform:
- FFT (Row 0) center is at `y = 0.5 / 2.0 = 0.25`.
- Waveform (Row 1) center is at `y = 1.5 / 2.0 = 0.75`.

```glsl
// Example: Get FFT magnitude at a normalized frequency 'u_freq' (0.0 to 1.0)
float fftMag = texture(iAudioTexture, vec2(u_freq, 0.25)).r;

// Example: Get waveform value at a normalized time 'u_time' (0.0 to 1.0)
float waveValRaw = texture(iAudioTexture, vec2(u_time, 0.75)).r;
float waveValSigned = (waveValRaw * 2.0) - 1.0; // Map back to -1.0 to 1.0

// Using texelFetch (GLSL ES 3.00) for precise integer coordinate access:
// ivec2 audioTexSize = textureSize(iAudioTexture, 0); // Get dimensions (e.g., 1024, 2)

// Fetch FFT from x-coordinate, row 0
// int fftXCoord = int(u_freq * float(audioTexSize.x));
// float fftMagFetched = texelFetch(iAudioTexture, ivec2(fftXCoord, 0), 0).r;

// Fetch Waveform from x-coordinate, row 1
// int waveXCoord = int(u_time * float(audioTexSize.x));
// float waveValFetchedRaw = texelFetch(iAudioTexture, ivec2(waveXCoord, 1), 0).r;
```
The `palpatine_bufferA.glsl` uses `texture2D(iAudioTexture, vec2(uvx, 1.0)).r;` for waveform, which implies the y-coordinate for waveform is `1.0` (or very close to the top edge of the texture). Given `VisualizationCanvas.js` fills row 0 (index 0) with FFT and row 1 (index 1) with waveform, and GL texture coordinates typically run from 0.0 (bottom/left) to 1.0 (top/right):
- FFT is at y normalized coordinate `0.0 / (textureHeight - 1)` if height is 2. This is `0.0`.
- Waveform is at y normalized coordinate `1.0 / (textureHeight -1)`. This is `1.0`.

So, for a 1024x2 texture:
-   **FFT Data**: Sample at `vec2(u_freq, 0.0)` or `ivec2(x_coord, 0)` for `texelFetch`.
-   **Waveform Data**: Sample at `vec2(u_time, 1.0)` or `ivec2(x_coord, 1)` for `texelFetch`.

The `radial_fft_line.glsl` uses `texture(iAudioTexture, vec2(u_tex_coord, 0.25)).x;`. This suggests a slight vertical offset. It's safer to use `0.0` for FFT and `1.0` for waveform if the texture is indeed 2 pixels high and data is packed tightly. `VisualizationCanvas.js` confirms data is packed into row 0 (FFT) and row 1 (Waveform) of a `textureHeight = 2` texture.

Corrected `iAudioTexture` y-coordinates based on `VisualizationCanvas.js` logic and standardizing to sample texel centers:
- **FFT Data:** Sample at `vec2(u_freq, 0.25)` (center of row 0 for a 2-pixel high texture).
- **Waveform Data:** Sample at `vec2(u_time, 0.75)` (center of row 1 for a 2-pixel high texture).

Given `texture()` samples centers of texels, and `texelFetch()` uses integer coordinates:
- FFT (row 0): `texelFetch(iAudioTexture, ivec2(x, 0), 0).r` or `texture(iAudioTexture, vec2(u_freq, 0.25)).r`
- Waveform (row 1): `texelFetch(iAudioTexture, ivec2(x, 1), 0).r` or `texture(iAudioTexture, vec2(u_time, 0.75)).r`
The current examples like `palpatine_bufferA.glsl` using `vec2(uvx, 1.0)` for waveform and `radial_fft_line.glsl` using `vec2(u_tex_coord, 0.25)` for FFT are likely working due to linear filtering or slight inaccuracies being visually acceptable. For precision, using coordinates that target the center of the texel rows is best.

## Shader Structure

All shaders must be GLSL ES 3.00.

```glsl
#version 300 es
#ifdef GL_ES
precision highp float;
precision highp int;
precision mediump sampler3D; // Though 3D textures are not typically used
#endif

// Your uniforms (if any, beyond the standard ones)
// uniform float iMyCustomUniform;

// Helper functions (optional)

void mainImage(out vec4 fragColor, in vec2 fragCoord) {
    // Your pixel shader logic here
    // fragCoord.xy is the current pixel coordinate.
    // To get normalized UVs (0.0 to 1.0):
    vec2 uv = fragCoord.xy / iResolution.xy;

    // ... calculate color ...
    vec3 col = vec3(uv.x, uv.y, 0.5 + 0.5 * sin(iTime));

    fragColor = vec4(col, 1.0); // Output RGBA
}
```

The `ShaderToyLite.js` header (lines 3-29) automatically includes `#define texture2D texture`.

## Resolution Scaling

Shaders can specify a rendering resolution scale different from the display resolution for performance or artistic effects. This is done via a comment in the **image pass shader file** (or the single .glsl file if not multi-pass):

```glsl
// resolution: 0.5
```

This example would render the shader at half the display resolution.
-   `1.0` (Default): Full resolution.
-   `0.5`: Half resolution (width/2, height/2).
-   `2.0`: Double resolution (width*2, height*2) - use with extreme caution.

`VisualizationCanvas.js` parses this comment. If not found, it defaults to `1.0`.

## Multi-Pass Shaders

Multi-pass shaders allow for more complex effects by rendering intermediate steps to buffers (textures) that can be used as inputs in subsequent passes.

**Naming Convention:**

If your effect is named `my_effect`, the files would be:

-   `my_effect_bufferA.glsl`
-   `my_effect_bufferB.glsl` (optional)
-   `my_effect_bufferC.glsl` (optional)
-   `my_effect_bufferD.glsl` (optional)
-   `my_effect_image.glsl` (This is the final pass rendered to the screen)
-   `my_effect_common.glsl` (Optional, for shared functions across passes)

The corresponding JSON effect definition (`effects/my_effect.json`) would point to the base name:

```json
{
  "name": "My Effect",
  "shader": "shaders/my_effect" // Note: no _image.glsl suffix here
  // ... other properties ...
}
```

`superColliderManager.js` (`loadMultiPassShader` function) and `main.js` (`reloadShaderEffect` function) handle loading these files based on the base name.

**Buffer Configuration in `VisualizationCanvas.js`:**

-   **Self-Referencing Buffers**: Buffers A, B, C, and D are configured to use their own previous frame's output as `iChannel0` by default if they exist (e.g., Buffer A's `iChannel0` is the previous state of Buffer A). This is for feedback effects.
    ```javascript
    // Example from VisualizationCanvas.js for Buffer A
    toy.setBufferA({
        source: shaderCodeToUse.bufferA,
        iChannel0: "A" // "A" means Buffer A uses itself as input on iChannel0
    });
    ```
-   **Image Pass Channel Mapping**: The `image` pass automatically gets its `iChannel`s mapped to the available buffers:
    -   `iChannel0` <- Buffer A output
    -   `iChannel1` <- Buffer B output
    -   `iChannel2` <- Buffer C output
    -   `iChannel3` <- Buffer D output

**Example: `oscilloscope` effect (`effects/oscilloscope.json`)**

```json
{
  "name": "Oscilloscope",
  "description": "a classic oscilloscope visualization with waveform and FFT display",
  "audio": "audio/oscilloscope.sc",
  "shader": "shaders/oscilloscope", // Base name
  "curated": true,
  "params": []
}
```
This implies `shaders/oscilloscope_bufferA.glsl` and `shaders/oscilloscope_image.glsl` (and potentially `_common.glsl`, `_bufferB.glsl` etc.) exist.

-   `oscilloscope_bufferA.glsl`: Likely calculates something and writes to Buffer A. It can read its own previous state from `iChannel0`.
-   `oscilloscope_image.glsl`: Reads from `iChannel0` (which is the output of Buffer A) and renders the final image.

**Example: `palpatine` effect**
The files `palpatine_bufferA.glsl` and `palpatine_image.glsl` follow this convention.
-   `palpatine_bufferA.glsl`:
    ```glsl
    // Samples previous frame (from iChannel0, which is this buffer's last output)
    vec4 prev = texture(iChannel0, uv);
    // ... diffusion logic ...
    // vec3 col = diffusion.rgb;
    // col += wave * waveColor;
    // fragColor = vec4(col, 1.0);
    ```
-   `palpatine_image.glsl`:
    ```glsl
    // vec3 buffer = texture(iChannel0, uv).rgb; // Reads output of palpatine_bufferA
    // vec3 wave = sdSound(...) * vec3(0.6, 0.2, 1.0);
    // fragColor = vec4(buffer * .2 + wave, 1.0);
    ```

## Custom Uniforms

If your shader requires custom parameters (e.g., knobs, sliders), these need to be:
1.  Defined in the effect's `.json` file (in the `params` array).
2.  Declared as `uniform` in your GLSL shader.
3.  The application (`App.js` and `VisualizationCanvas.js`) needs to be aware of how to send these values to the shader. Currently, `paramValuesRef.current` is passed to p5.js sketches. For ShaderToyLite, a mechanism to update arbitrary uniforms from the `params` array would need to be ensured or implemented if not already generic. `ShaderToyLite.js` has locations for standard uniforms; custom ones would need their locations fetched and updated in the render loop if they change.

## GLSL Best Practices & Tips

-   **Precision**: Use `highp` for `float` and `int` where precision is critical, especially for calculations involving positions or colors. `mediump` can be used for texture coordinates or less critical calculations if performance is a concern, but `highp` is a safe default.
-   **Optimize**: Shader performance is key. Avoid complex loops, unnecessary calculations, and excessive texture lookups if possible.
-   **Vectorize**: Use vector operations (e.g., `vec3 * float` instead of multiplying each component separately).
-   **Built-in Functions**: Utilize GLSL's rich set of built-in functions (`sin`, `cos`, `mix`, `clamp`, `smoothstep`, `length`, `normalize`, `atan`, etc.).
-   **Constants**: Use `const` for values that don't change. Use `#define` for preprocessor constants, which can be useful for defining parameters related to audio analysis or visual layout (see `radial_fft_line.glsl` for examples like `SAMPLERATE`, `NUM_OCTAVES_DISPLAY`).
-   **Coordinate Systems & Aspect Ratio**:
    -   For screen-space effects, normalize coordinates: `vec2 uv = fragCoord.xy / iResolution.xy;`.
    -   For effects requiring consistent aspect ratio (e.g., circles, radial patterns), consider normalizing by one dimension, typically height: `vec2 uv_centered = fragCoord.xy - 0.5 * iResolution.xy; vec2 uv_aspect_corrected = uv_centered / iResolution.y;`.
    -   Polar coordinates (`atan(y,x)` for angle, `length(vec)` for radius) are useful for radial effects.
-   **Audio-Reactive Techniques (from `radial_fft_line.glsl`):**
    -   **Frequency Mapping**: Convert musical notes (e.g., MIDI) to frequencies (`freq = A4_FREQ * pow(2.0, (midiNote - A4_MIDI_NOTE) / 12.0);`).
    -   **FFT Bin Calculation**: Map these frequencies to specific bins in the `iAudioTexture`'s FFT data. This involves knowing the `SAMPLERATE` and FFT size used by SuperCollider (e.g., `FFT_ANALYSIS_SIZE_SC`) to calculate `sc_bin_freq_step = SAMPLERATE / FFT_ANALYSIS_SIZE_SC;` and then `target_sc_bin_float = freq / sc_bin_freq_step;`.
    -   **Normalized Texture Coordinates**: Convert the target bin to a normalized U-coordinate for `iAudioTexture`: `u_tex_coord = target_sc_bin_float / NUM_FFT_BINS_IN_TEXTURE;` (where `NUM_FFT_BINS_IN_TEXTURE` is the number of bins packed into the texture, e.g., 512).
    -   **FFT Data Interpretation**: Remember that FFT data in `iAudioTexture` (sampled at `y=0.25`) is typically pre-processed (e.g., logarithmically scaled magnitudes) and normalized. Adapt your shader logic accordingly.
-   **SDF-like Rendering**: For drawing smooth, anti-aliased shapes (lines, circles), `smoothstep` can be used to create soft edges based on distance to the shape's surface. This is a common technique in Signed Distance Field rendering.
-   **Debugging**:
    -   Output intermediate values as colors to visualize them (e.g., `fragColor = vec4(myVar, 0.0, 0.0, 1.0);`).
    -   Start simple and add complexity incrementally.
    -   Check the browser's JavaScript console for shader compilation errors. `ShaderToyLite.js` logs these.

## Example: `radial_fft_line.glsl` (Single Pass Shader)

This shader demonstrates:
-   Use of `iResolution`, `iTime`, `iAudioTexture`.
-   Conversion of FFT data to visual elements.
-   Defines (`PI`, `SAMPLERATE`).
-   Helper functions (`midiToFreq`, `getNormalizedFFTForMidiNote`).

```glsl
// (Relevant snippets from radial_fft_line.glsl)
#define PI 3.14159265359
// ... other defines ...

// Accessing iAudioTexture for FFT
// float fft_mag_log10 = texture(iAudioTexture, vec2(u_tex_coord, 0.25)).x;
// Corrected based on analysis:
float fft_mag_log10 = texture(iAudioTexture, vec2(u_tex_coord, 0.25)).x; // Target center of texel row 0

void mainImage( out vec4 fragColor, in vec2 fragCoord ) {
    vec2 uv_center_offset = fragCoord.xy - 0.5 * iResolution.xy;
    vec2 uv = uv_center_offset / iResolution.y; // Normalized by height for aspect
    // ...
    fragColor = vec4(finalPixelColor, 1.0);
}
```

## Summary Checklist for New Shaders

1.  **File Location**: `bice-box-effects/shaders/your_shader_name.glsl` (or `_pass.glsl` for multi-pass).
2.  **GLSL Version**: `#version 300 es`. Add precision header.
3.  **`mainImage` Function**: Define `void mainImage(out vec4 fragColor, in vec2 fragCoord)`.
4.  **Standard Uniforms**: Use them directly; do not redeclare.
5.  **`iAudioTexture`**:
    -   Sample FFT at `y = 0.25` (e.g., `texture(iAudioTexture, vec2(u_freq, 0.25)).r`).
    -   Sample Waveform at `y = 0.75` (e.g., `texture(iAudioTexture, vec2(u_time, 0.75)).r`). Map 0-1 back to -1 to 1 if needed.
6.  **Resolution**: If not 1.0, specify `// resolution: X.X` in the image pass.
7.  **Multi-Pass**:
    -   Follow `_bufferA`, `_image`, `_common` naming.
    -   Update effect JSON `shader` field to base name (e.g., `shaders/my_effect`).
    -   Remember buffer self-referencing (`iChannel0 = "A"`) and image pass auto-mapping.
8.  **Effect JSON**: Create/update the corresponding `.json` file in `bice-box-effects/effects/`.
9.  **Test Thoroughly**: Check for compilation errors in the console and visual correctness.

This guide should provide a solid foundation for developing new GLSL shaders for BICE Box.
Refer to existing shaders in the `bice-box-effects/shaders/` directory for more examples.
